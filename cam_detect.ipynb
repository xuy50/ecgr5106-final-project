{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f438edf0",
   "metadata": {},
   "source": [
    "XAI Comparison: Grad-CAM vs LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e159b",
   "metadata": {},
   "source": [
    "Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch & Vision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Pretrained model\n",
    "import timm\n",
    "\n",
    "# Grad-CAM\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "# LIME\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Dataset / Metrics\n",
    "import pandas as pd\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdcf55",
   "metadata": {},
   "source": [
    "Load Model & Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419bd860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Reconstruct model architecture, load weights\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "model.head = nn.Linear(model.head.in_features, 2)\n",
    "# load saved state dict (remove 'module.' if necessary)\n",
    "state = torch.load('models/vit_ai_detection_10.pth', map_location=device)\n",
    "new_state = {}\n",
    "for k,v in state.items():\n",
    "    name = k.replace('module.','') \n",
    "    new_state[name] = v\n",
    "model.load_state_dict(new_state)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 2) Prepare test dataset (same transform as training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.df['file_name'] = self.df['file_name'].apply(lambda x: os.path.join(root_dir, x))\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.df.iloc[idx]['file_name']).convert('RGB')\n",
    "        label = int(self.df.iloc[idx]['label'])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "test_dataset = ImageDataset('datasets/test.csv', 'datasets', transform=transform)\n",
    "# pick one sample\n",
    "image_tensor, true_label = test_dataset[0]\n",
    "# for visualization later:\n",
    "rgb = image_tensor.permute(1,2,0).cpu().numpy()\n",
    "rgb_vis = (rgb*0.5 + 0.5).clip(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a0b46",
   "metadata": {},
   "source": [
    "Grad-CAM Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df05a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape_transform for ViT (remove class token, reshape to H×W)\n",
    "def reshape_transform(tensor, height=14, width=14):\n",
    "    result = tensor[:,1:,:].reshape(tensor.size(0), height, width, tensor.size(2))\n",
    "    return result.permute(0,3,1,2)\n",
    "\n",
    "# unwrap DataParallel if used\n",
    "base_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "\n",
    "# choose the last transformer block’s norm1\n",
    "target_layers = [base_model.blocks[-1].norm1]\n",
    "\n",
    "cam = GradCAM(\n",
    "    model=base_model,\n",
    "    target_layers=target_layers,\n",
    "    reshape_transform=reshape_transform,\n",
    "    use_cuda=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# prepare input batch\n",
    "input_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "targets = [ClassifierOutputTarget(true_label)]\n",
    "\n",
    "# compute CAM\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]\n",
    "# overlay\n",
    "cam_vis = show_cam_on_image(rgb_vis, grayscale_cam, use_rgb=True)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(cam_vis)\n",
    "plt.title(f\"Grad-CAM (True={true_label})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0446c",
   "metadata": {},
   "source": [
    "LIME Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7163c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image to uint8 HWC for LIME\n",
    "rgb_uint8 = (rgb_vis * 255).astype(np.uint8)\n",
    "\n",
    "# define the wrapper for LIME\n",
    "def predict_fn(images):\n",
    "    model.eval()\n",
    "    batch = []\n",
    "    for img in images:\n",
    "        # HWC uint8 -> CHW float tensor\n",
    "        t = TF.to_tensor(Image.fromarray(img))\n",
    "        t = TF.resize(t, (224,224))\n",
    "        t = TF.normalize(t, [0.5]*3, [0.5]*3)\n",
    "        batch.append(t)\n",
    "    batch = torch.stack(batch).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch)\n",
    "        probs  = F.softmax(logits, dim=1).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(\n",
    "    rgb_uint8,\n",
    "    classifier_fn=predict_fn,\n",
    "    top_labels=2,\n",
    "    hide_color=0,\n",
    "    num_samples=1000\n",
    ")\n",
    "\n",
    "# get mask for the true class\n",
    "temp, mask = explanation.get_image_and_mask(\n",
    "    true_label, positive_only=True, num_features=10, hide_rest=False\n",
    ")\n",
    "\n",
    "# visualize\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(mark_boundaries(temp, mask))\n",
    "plt.title(f\"LIME (True={true_label})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
